{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install statsmodels\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Npm1haQ2WYhB",
        "outputId": "dad76987-bb40-4ba3-f8bd-d94399775814"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: statsmodels in /usr/local/lib/python3.11/dist-packages (0.14.4)\n",
            "Requirement already satisfied: numpy<3,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from statsmodels) (2.0.2)\n",
            "Requirement already satisfied: scipy!=1.9.2,>=1.8 in /usr/local/lib/python3.11/dist-packages (from statsmodels) (1.14.1)\n",
            "Requirement already satisfied: pandas!=2.1.0,>=1.4 in /usr/local/lib/python3.11/dist-packages (from statsmodels) (2.2.2)\n",
            "Requirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.11/dist-packages (from statsmodels) (1.0.1)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.11/dist-packages (from statsmodels) (24.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas!=2.1.0,>=1.4->statsmodels) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix\n",
        "from statsmodels.stats.weightstats import ztest\n",
        "\n",
        "\n",
        "# Load dataset\n",
        "url = \"/content/diabetes_data_upload.csv\"\n",
        "df = pd.read_csv(url)\n",
        "\n",
        "# Encode categorical variables\n",
        "le = LabelEncoder()\n",
        "for col in df.select_dtypes(include=['object']).columns:\n",
        "    df[col] = le.fit_transform(df[col])\n",
        "\n",
        "# Split features and target\n",
        "X = df.drop(columns=['class'])\n",
        "y = df['class']\n",
        "\n",
        "# Train-test split (80-20)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize numerical features\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Train models\n",
        "models = {\n",
        "    \"Logistic Regression\": LogisticRegression(),\n",
        "    \"Decision Tree\": DecisionTreeClassifier(),\n",
        "    \"Random Forest\": RandomForestClassifier(),\n",
        "    \"SVM\": SVC(probability=True),\n",
        "    \"KNN\": KNeighborsClassifier(),\n",
        "    \"Gradient Boosting\": GradientBoostingClassifier()\n",
        "}\n",
        "\n",
        "results = {}\n",
        "conf_matrices = {}\n",
        "\n",
        "for name, model in models.items():\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred)\n",
        "    recall = recall_score(y_test, y_pred)\n",
        "\n",
        "    conf_matrices[name] = cm\n",
        "    results[name] = {\n",
        "        \"Accuracy\": accuracy,\n",
        "        \"Precision\": precision,\n",
        "        \"Recall\": recall,\n",
        "        \"False Positive Rate\": cm[0][1] / (cm[0][1] + cm[0][0]),  # Type I error\n",
        "        \"False Negative Rate\": cm[1][0] / (cm[1][0] + cm[1][1])   # Type II error\n",
        "    }\n",
        "\n",
        "# Display results\n",
        "results_df = pd.DataFrame(results).T\n",
        "print(\"Model Performance:\\n\", results_df)\n",
        "\n",
        "# Identify model with lowest Type II error (false negatives)\n",
        "best_model = min(results, key=lambda x: results[x][\"False Negative Rate\"])\n",
        "print(f\"\\nBest model for minimizing undiagnosed diabetes cases: {best_model}\")\n",
        "\n",
        "# Z-Test on mean age of correctly vs. misclassified diabetic patients\n",
        "y_pred_lr = models[\"Logistic Regression\"].predict(X_test)\n",
        "misclassified_age = X_test[:, 0][(y_test != y_pred_lr)]\n",
        "correctly_classified_age = X_test[:, 0][(y_test == y_pred_lr)]\n",
        "\n",
        "z_stat, p_value = ztest(misclassified_age, correctly_classified_age)\n",
        "print(f\"\\nZ-Test on mean age difference (Correct vs. Misclassified): Z={z_stat:.2f}, p={p_value:.4f}\")\n",
        "\n",
        "# Significance check\n",
        "if p_value < 0.05:\n",
        "    print(\"There is a significant age difference. Consider adjusting model features.\")\n",
        "else:\n",
        "    print(\"No significant age difference. Age may not strongly influence classification.\")\n",
        "\n",
        "# Z-Test on false positive rate (Random Forest)\n",
        "rf_fpr = results[\"Random Forest\"][\"False Positive Rate\"]\n",
        "z_stat_rf, p_value_rf = ztest([rf_fpr], value=0.20)\n",
        "print(f\"\\nZ-Test for Random Forest FPR > 20%: Z={z_stat_rf:.2f}, p={p_value_rf:.4f}\")\n",
        "\n",
        "if p_value_rf < 0.05:\n",
        "    print(\"Random Forest false positive rate is significantly different from 20%. Consider feature selection or threshold tuning.\")\n",
        "else:\n",
        "    print(\"No significant difference from 20%. Adjustments may not be necessary.\")\n",
        "\n",
        "# Compare Type II errors (false negatives) for Logistic Regression, SVM, and KNN\n",
        "fn_lr = results[\"Logistic Regression\"][\"False Negative Rate\"]\n",
        "fn_svm = results[\"SVM\"][\"False Negative Rate\"]\n",
        "fn_knn = results[\"KNN\"][\"False Negative Rate\"]\n",
        "\n",
        "z_stat_fn, p_value_fn = ztest([fn_lr], [fn_svm])\n",
        "print(f\"\\nZ-Test on False Negative Rate (Logistic Regression vs. SVM): Z={z_stat_fn:.2f}, p={p_value_fn:.4f}\")\n",
        "\n",
        "# Final model recommendation\n",
        "best_overall_model = min(results, key=lambda x: results[x][\"False Negative Rate\"] + results[x][\"False Positive Rate\"])\n",
        "print(f\"\\nRecommended model for medical deployment: {best_overall_model}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dXOdJfkMWGHM",
        "outputId": "1e7ea545-7f1e-45dc-f03f-b8686f88ff00"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Performance:\n",
            "                      Accuracy  Precision    Recall  False Positive Rate  \\\n",
            "Logistic Regression  0.923077   0.931507  0.957746             0.151515   \n",
            "Decision Tree        0.942308   0.985075  0.929577             0.030303   \n",
            "Random Forest        0.990385   1.000000  0.985915             0.000000   \n",
            "SVM                  0.990385   0.986111  1.000000             0.030303   \n",
            "KNN                  0.894231   0.954545  0.887324             0.090909   \n",
            "Gradient Boosting    0.971154   1.000000  0.957746             0.000000   \n",
            "\n",
            "                     False Negative Rate  \n",
            "Logistic Regression             0.042254  \n",
            "Decision Tree                   0.070423  \n",
            "Random Forest                   0.014085  \n",
            "SVM                             0.000000  \n",
            "KNN                             0.112676  \n",
            "Gradient Boosting               0.042254  \n",
            "\n",
            "Best model for minimizing undiagnosed diabetes cases: SVM\n",
            "\n",
            "Z-Test on mean age difference (Correct vs. Misclassified): Z=-1.77, p=0.0770\n",
            "No significant age difference. Age may not strongly influence classification.\n",
            "\n",
            "Z-Test for Random Forest FPR > 20%: Z=nan, p=nan\n",
            "No significant difference from 20%. Adjustments may not be necessary.\n",
            "\n",
            "Z-Test on False Negative Rate (Logistic Regression vs. SVM): Z=nan, p=nan\n",
            "\n",
            "Recommended model for medical deployment: Random Forest\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/statsmodels/stats/weightstats.py:1559: RuntimeWarning: invalid value encountered in scalar divide\n",
            "  var = x1_var / (nobs1 - ddof)\n",
            "/usr/local/lib/python3.11/dist-packages/statsmodels/stats/weightstats.py:1554: RuntimeWarning: invalid value encountered in scalar divide\n",
            "  var /= nobs1 + nobs2 - 2 * ddof\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "F1XvElu3WGKk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}